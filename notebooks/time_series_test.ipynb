{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Using Keras to implement a 1D convolutional neural network (CNN) for timeseries prediction.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Input, Convolution1D, Dense, MaxPooling1D, Flatten, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "__date__ = '2018-08-07'\n",
    "\n",
    "\n",
    "def make_timeseries_regressor(window_size, kernel_size, nb_input_series=1, nb_outputs=1, filters=4):\n",
    "    \"\"\":Return: a Keras Model for predicting the next value in a timeseries given a fixed-size lookback window of previous values.\n",
    "\n",
    "    The model can handle multiple input timeseries (`nb_input_series`) and multiple prediction targets (`nb_outputs`).\n",
    "\n",
    "    :param int window_size: The number of previous timeseries values to use as input features.  Also called lag or lookback.\n",
    "    :param int nb_input_series: The number of input timeseries; 1 for a single timeseries.\n",
    "      The `X` input to ``fit()`` should be an array of shape ``(n_instances, window_size, nb_input_series)``; each instance is\n",
    "      a 2D array of shape ``(window_size, nb_input_series)``.  For example, for `window_size` = 3 and `nb_input_series` = 1 (a\n",
    "      single timeseries), one instance could be ``[[0], [1], [2]]``. See ``make_timeseries_instances()``.\n",
    "    :param int nb_outputs: The output dimension, often equal to the number of inputs.\n",
    "      For each input instance (array with shape ``(window_size, nb_input_series)``), the output is a vector of size `nb_outputs`,\n",
    "      usually the value(s) predicted to come after the last value in that input instance, i.e., the next value\n",
    "      in the sequence. The `y` input to ``fit()`` should be an array of shape ``(n_instances, nb_outputs)``.\n",
    "    :param int kernel_size: the size (along the `window_size` dimension) of the sliding window that gets convolved with\n",
    "      each position along each instance. The difference between 1D and 2D convolution is that a 1D filter's \"height\" is fixed\n",
    "      to the number of input timeseries (its \"width\" being `kernel_size`), and it can only slide along the window\n",
    "      dimension.  This is useful as generally the input timeseries have no spatial/ordinal relationship, so it's not\n",
    "      meaningful to look for patterns that are invariant with respect to subsets of the timeseries.\n",
    "    :param int filters: The number of different filters to learn (roughly, input patterns to recognize).\n",
    "    \"\"\"\n",
    "    \n",
    "    # The first conv layer learns `filters` filters (aka kernels), each of size ``(kernel_size, nb_input_series)``.\n",
    "    # Its output will have shape (None, window_size - kernel_size + 1, filters), i.e., for each position in\n",
    "    # the input timeseries, the activation of each filter at that position.\n",
    "        \n",
    "    inputs = Input(shape=(window_size, nb_input_series))\n",
    "    x = Convolution1D(filters, 1, padding='causal', name='initial_conv')(inputs)\n",
    "    x = Convolution1D(activation='relu', filters=filters, kernel_size=kernel_size, padding='causal', dilation_rate=1)(x)\n",
    "    #x = MaxPooling1D()(x) # Downsample the output of convolution by 2X.\n",
    "    x = Convolution1D(activation='relu', filters=filters, kernel_size=kernel_size, padding='causal', dilation_rate=2)(x)\n",
    "    #x = MaxPooling1D()(x)\n",
    "    x = Convolution1D(activation='relu', filters=filters, kernel_size=kernel_size, padding='causal', dilation_rate=4)(x)\n",
    "    x = Flatten()(x)\n",
    "    preds = Dense(nb_outputs, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    # To perform (binary) classification instead:\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    \"\"\"Make input features and prediction targets from a `timeseries` for use in machine learning.\n",
    "\n",
    "    :return: A tuple of `(X, y, q)`.  `X` are the inputs to a predictor, a 3D ndarray with shape\n",
    "      ``(timeseries.shape[0] - window_size, window_size, timeseries.shape[1] or 1)``.  For each row of `X`, the\n",
    "      corresponding row of `y` is the next value in the timeseries.  The `q` or query is the last instance, what you would use\n",
    "      to predict a hypothetical next (unprovided) value in the `timeseries`.\n",
    "    :param ndarray timeseries: Either a simple vector, or a matrix of shape ``(timestep, series_num)``, i.e., time is axis 0 (the\n",
    "      row) and the series is axis 1 (the column).\n",
    "    :param int window_size: The number of samples to use as input prediction features (also called the lag or lookback).\n",
    "    \"\"\"\n",
    "    timeseries = np.asarray(timeseries)\n",
    "    assert 0 < window_size < timeseries.shape[0]\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    q = []\n",
    "    \n",
    "    for start in range(0, timeseries.shape[0] - window_size):\n",
    "        X.append(np.array(timeseries[start:start + window_size]))\n",
    "        y.append(np.array(timeseries[start + window_size]))\n",
    "        q.append([timeseries[-(start + window_size):]])\n",
    "        \n",
    "    X = np.atleast_3d(X)\n",
    "    y = np.asarray(y)\n",
    "    q = np.atleast_3d(q)\n",
    "        \n",
    "    print(\"X\", X.shape)\n",
    "#     print(X)\n",
    "#     print()\n",
    "    \n",
    "    print(\"y\", y.shape)\n",
    "#     print(y)\n",
    "#     print()\n",
    "    \n",
    "#     X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "#     y = timeseries[window_size:]\n",
    "#     print('y', y.shape, y)\n",
    "    q = np.atleast_3d([timeseries[-window_size:]])\n",
    "    return X, y, q\n",
    "\n",
    "\n",
    "def evaluate_timeseries(timeseries, window_size):\n",
    "    \"\"\"Create a 1D CNN regressor to predict the next value in a `timeseries` using the preceding `window_size` elements\n",
    "    as input features and evaluate its performance.\n",
    "\n",
    "    :param ndarray timeseries: Timeseries data with time increasing down the rows (the leading dimension/axis).\n",
    "    :param int window_size: The number of previous timeseries values to use to predict the next.\n",
    "    \"\"\"\n",
    "    kernel_size = 5\n",
    "    filters = 4\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T       # Convert 1D vectors to 2D column vectors\n",
    "\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "    print('\\n\\nTimeseries ({} samples by {} series):\\n'.format(nb_samples, nb_series), timeseries)\n",
    "    model = make_timeseries_regressor(window_size=window_size, kernel_size=kernel_size, nb_input_series=nb_series, nb_outputs=nb_series, filters=filters)\n",
    "    print('\\n\\nModel with input size {}, output size {}, {} conv filters of length {}'.format(model.input_shape, model.output_shape, filters, kernel_size))\n",
    "    model.summary()\n",
    "\n",
    "    X, y, q = make_timeseries_instances(timeseries, window_size)\n",
    "    \n",
    "    #epochs = int(np.sqrt(X.shape[0] * X.shape[1]))\n",
    "    epochs = X.shape[0] * X.shape[1]\n",
    "    print(\"epochs \", epochs)\n",
    "    \n",
    "    print('\\n\\nInput features:', X, '\\n\\nOutput labels:', y, '\\n\\nQuery vector:', q, sep='\\n')\n",
    "    test_size = int(0.2 * nb_samples)           \n",
    "    X_train, X_test, y_train, y_test = X[:-test_size], X[-test_size:], y[:-test_size], y[-test_size:]\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=256, verbose=False)\n",
    "\n",
    "\n",
    "#     pred = model.predict(X_test)\n",
    "#     print('\\n\\nactual', 'predicted', sep='\\t')\n",
    "#     for actual, predicted in zip(y_test, pred.squeeze()):\n",
    "#         print(actual.squeeze(), predicted, sep='\\t')\n",
    "#     print('next', model.predict(q).squeeze(), sep='\\t')\n",
    "    \n",
    "    print()\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('(loss, mean_absolute_error, mean_squared_error) = ', score)\n",
    "\n",
    "\n",
    "def play():\n",
    "    \"\"\"Prepare input data, build model, evaluate.\"\"\"\n",
    "    np.set_printoptions(threshold=25)\n",
    "    ts_length = 1000\n",
    "    window_size = 50\n",
    "\n",
    "    print('\\nSimple single timeseries vector prediction')\n",
    "    timeseries = np.arange(ts_length)                   # The timeseries f(t) = t\n",
    "    evaluate_timeseries(timeseries, window_size)\n",
    "\n",
    "    print('\\nMultiple-input, multiple-output prediction')\n",
    "    timeseries = np.array([np.arange(ts_length), -np.arange(ts_length)]).T      # The timeseries f(t) = [t, -t]\n",
    "    evaluate_timeseries(timeseries, window_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timeseries(snap_fname):\n",
    "    time_series_len = 128\n",
    "    timeseries = []\n",
    "    with open(snap_fname, 'r') as fin:\n",
    "        for l in fin:\n",
    "            tokens = l.strip().split('\\t')\n",
    "            if len(tokens) != time_series_len:\n",
    "                continue\n",
    "            \n",
    "            timeseries.append([float(x) for x in tokens])\n",
    "    # Transposing to make time = the rows (axis=0)\n",
    "    timeseries = np.asarray(timeseries).T\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_m4_timeseries(fname):\n",
    "    data = pd.read_csv(fname)\n",
    "    data = data.fillna(0)\n",
    "    data = data.drop(columns=['V1']).values.T\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeseries = load_timeseries(\"MemePhr.txt\")\n",
    "fname = '/Users/bluebalam/projectsX/libreai/projects/minerva_experimental/minerva/minerva/M4_benchmark/M4-methods/Dataset/Train/Quarterly-train.csv'\n",
    "timeseries = load_m4_timeseries(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = timeseries[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7407.41231382, 7552.45461911, 8463.8421932 , 8498.94119397],\n",
       "       [7528.5660743 , 7541.77457066, 8366.10230911, 8409.92644199],\n",
       "       [7374.70922497, 7466.56833608, 8269.50219151, 8391.44138144],\n",
       "       [7395.51484763, 7550.33335403, 8256.98532453, 8292.86031049],\n",
       "       [7654.00798853, 8067.13152222, 8726.91764696, 8798.52111766],\n",
       "       [7686.84783506, 8063.70101739, 8733.24359072, 8753.99035458],\n",
       "       [7578.19074266, 7901.02931239, 8664.26008696, 8740.06255558],\n",
       "       [7904.37671607, 8155.38731599, 8717.39456788, 8695.54065076],\n",
       "       [7744.04925353, 8031.01032808, 8662.13972695, 8627.44748783],\n",
       "       [7889.90901325, 8023.24000549, 8629.10189569, 8525.99342353]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[:10,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Timeseries (866 samples by 15 series):\n",
      " [[7407.41231382 7552.45461911 8463.8421932  ...  926.9\n",
      "  5370.         1527.        ]\n",
      " [7528.5660743  7541.77457066 8366.10230911 ...  953.5\n",
      "  4940.         1576.        ]\n",
      " [7374.70922497 7466.56833608 8269.50219151 ...  945.1\n",
      "  5660.         1641.        ]\n",
      " ...\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]]\n",
      "\n",
      "\n",
      "Model with input size (None, 4, 15), output size (None, 15), 4 conv filters of length 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 4, 15)             0         \n",
      "_________________________________________________________________\n",
      "initial_conv (Conv1D)        (None, 4, 4)              64        \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 4, 4)              84        \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 4, 4)              84        \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 4, 4)              84        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                255       \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X (862, 4, 15)\n",
      "y (862, 15)\n",
      "epochs  3448\n",
      "\n",
      "\n",
      "Input features:\n",
      "[[[7407.41231382 7552.45461911 8463.8421932  ...  926.9\n",
      "   5370.         1527.        ]\n",
      "  [7528.5660743  7541.77457066 8366.10230911 ...  953.5\n",
      "   4940.         1576.        ]\n",
      "  [7374.70922497 7466.56833608 8269.50219151 ...  945.1\n",
      "   5660.         1641.        ]\n",
      "  [7395.51484763 7550.33335403 8256.98532453 ...  939.7\n",
      "   5660.         1599.        ]]\n",
      "\n",
      " [[7528.5660743  7541.77457066 8366.10230911 ...  953.5\n",
      "   4940.         1576.        ]\n",
      "  [7374.70922497 7466.56833608 8269.50219151 ...  945.1\n",
      "   5660.         1641.        ]\n",
      "  [7395.51484763 7550.33335403 8256.98532453 ...  939.7\n",
      "   5660.         1599.        ]\n",
      "  [7654.00798853 8067.13152222 8726.91764696 ...  974.1\n",
      "   5780.         1613.        ]]\n",
      "\n",
      " [[7374.70922497 7466.56833608 8269.50219151 ...  945.1\n",
      "   5660.         1641.        ]\n",
      "  [7395.51484763 7550.33335403 8256.98532453 ...  939.7\n",
      "   5660.         1599.        ]\n",
      "  [7654.00798853 8067.13152222 8726.91764696 ...  974.1\n",
      "   5780.         1613.        ]\n",
      "  [7686.84783506 8063.70101739 8733.24359072 ...  989.6\n",
      "   5920.         1516.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]]\n",
      "\n",
      " [[   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.            0.        ]]]\n",
      "\n",
      "\n",
      "Output labels:\n",
      "[[7654.00798853 8067.13152222 8726.91764696 ...  974.1\n",
      "  5780.         1613.        ]\n",
      " [7686.84783506 8063.70101739 8733.24359072 ...  989.6\n",
      "  5920.         1516.        ]\n",
      " [7578.19074266 7901.02931239 8664.26008696 ...  999.2\n",
      "  6410.         1571.        ]\n",
      " ...\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]\n",
      " [   0.            0.            0.         ...    0.\n",
      "     0.            0.        ]]\n",
      "\n",
      "\n",
      "Query vector:\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "\n",
      "(loss, mean_absolute_error, mean_squared_error) =  [0.03963237628340721, 0.173063725233078, 0.03963237628340721]\n"
     ]
    }
   ],
   "source": [
    "window_size = 4\n",
    "#make_timeseries_instances(timeseries[:16,:4], window_size)\n",
    "#evaluate_timeseries(timeseries[:16,:4], window_size)\n",
    "evaluate_timeseries(timeseries, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
